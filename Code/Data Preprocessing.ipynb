{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eda70079",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf0d1c9",
   "metadata": {},
   "source": [
    "This notebook contains code to preprocess GDP and Stock Market data for CSE 512 Model vs Modalities project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9c4abb",
   "metadata": {},
   "source": [
    "## Part I (Data Aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a251db8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3992fac6",
   "metadata": {},
   "source": [
    "In this section, we will aggregate data from multiple files and different file types, into a single CSV with required variables and timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f7e8979",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = \"../Raw_Data/\"\n",
    "processed_data_path = \"../Processed_Data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6353e3fe",
   "metadata": {},
   "source": [
    "### Stock Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00a925a",
   "metadata": {},
   "source": [
    "Read data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8a0813b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame()\n",
    "\n",
    "for file in ['DIA', 'EEM', 'QQQ', 'SPY', 'VXX']:\n",
    "    with open(os.path.join(raw_data_path, file) + '.txt') as f:\n",
    "        data = f.readlines()\n",
    "        data = [line.strip().split(\",\") for line in data]\n",
    "        data = pd.DataFrame(data, columns=['datetime', 'open', 'high', 'low', 'close', 'volume'])\n",
    "        data = data[['datetime', 'close']]\n",
    "        data['close'] = data['close'].astype(float)\n",
    "        data.columns = ['datetime', file]\n",
    "        \n",
    "        if final_df.shape[0] == 0:\n",
    "            final_df = data\n",
    "        else:\n",
    "            final_df = pd.merge(\n",
    "                final_df,\n",
    "                data,\n",
    "                how='left',\n",
    "                on='datetime'\n",
    "            )\n",
    "            \n",
    "final_df['datetime'] = pd.to_datetime(final_df['datetime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a662262",
   "metadata": {},
   "source": [
    "Interpolate missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d4fbdae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_frame = pd.DataFrame(pd.date_range(start=final_df['datetime'].min(), end=final_df['datetime'].max(), freq='1min'))\n",
    "time_frame.columns = ['datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00840770",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_frame = time_frame[time_frame['datetime'].astype(str).str.split(' ').apply(lambda x: x[1] <= '16:00:00')]\n",
    "time_frame = time_frame[time_frame['datetime'].astype(str).str.split(' ').apply(lambda x: x[1] >= '09:30:00')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d416de7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.merge(\n",
    "    time_frame,\n",
    "    final_df,\n",
    "    how='left',\n",
    "    on='datetime'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3201ba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['date'] = final_df['datetime'].dt.date\n",
    "temp_df = final_df.fillna(-1).groupby('date')['DIA'].sum()\n",
    "final_df = final_df[~final_df['date'].isin(temp_df[temp_df == -391].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "080c9a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing subset of data where we have minimal missing values\n",
    "final_df = final_df.iloc[40273:]\n",
    "final_df = final_df.drop(columns='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81fe9b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b123e254",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.set_index('datetime')\n",
    "final_df.to_csv(os.path.join(processed_data_path, 'etf_data.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7409a9bc",
   "metadata": {},
   "source": [
    "### GDP Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c7786cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_data = pd.read_csv(raw_data_path + 'quarterly_GDP.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cca8ea61",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_columns = ['DATE', 'Tbill', 'PPINSA', 'CPI', 'M1NSA', 'Unemp', 'IndProd', 'RGDP']\n",
    "\n",
    "gdp_data = gdp_data[select_columns]\n",
    "gdp_data = gdp_data.set_index('DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d6282c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_data.to_csv(os.path.join(processed_data_path, 'gdp_data.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bcf794",
   "metadata": {},
   "source": [
    "## Part 2 (Preprocessing Tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7503b8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tools.eval_measures import rmse, aic\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "\n",
    "import utilities as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c727dd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = \"../Raw_Data/\"\n",
    "processed_data_path = \"../Processed_Data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767834e3",
   "metadata": {},
   "source": [
    "### Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "914c58fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_data = pd.read_csv(os.path.join(processed_data_path, \"etf_data.csv\"), index_col='datetime')\n",
    "stocks_data = stocks_data.iloc[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ac5315e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Augmented Dickey-Fuller Test on \"DIA\" \n",
      " -----------------------------------------------\n",
      " Null Hypothesis: Data has unit root. Non-Stationary.\n",
      " Significance Level    = 0.05\n",
      " Test Statistic        = -2.1598\n",
      " No. Lags Chosen       = 1\n",
      " Critical value 1%     = -3.431\n",
      " Critical value 5%     = -2.862\n",
      " Critical value 10%    = -2.567\n",
      " => P-Value = 0.2212. Weak evidence to reject the Null Hypothesis.\n",
      " => Series is Non-Stationary.\n",
      "\n",
      "\n",
      "    Augmented Dickey-Fuller Test on \"EEM\" \n",
      " -----------------------------------------------\n",
      " Null Hypothesis: Data has unit root. Non-Stationary.\n",
      " Significance Level    = 0.05\n",
      " Test Statistic        = -1.8445\n",
      " No. Lags Chosen       = 2\n",
      " Critical value 1%     = -3.431\n",
      " Critical value 5%     = -2.862\n",
      " Critical value 10%    = -2.567\n",
      " => P-Value = 0.3586. Weak evidence to reject the Null Hypothesis.\n",
      " => Series is Non-Stationary.\n",
      "\n",
      "\n",
      "    Augmented Dickey-Fuller Test on \"QQQ\" \n",
      " -----------------------------------------------\n",
      " Null Hypothesis: Data has unit root. Non-Stationary.\n",
      " Significance Level    = 0.05\n",
      " Test Statistic        = -1.4288\n",
      " No. Lags Chosen       = 1\n",
      " Critical value 1%     = -3.431\n",
      " Critical value 5%     = -2.862\n",
      " Critical value 10%    = -2.567\n",
      " => P-Value = 0.5684. Weak evidence to reject the Null Hypothesis.\n",
      " => Series is Non-Stationary.\n",
      "\n",
      "\n",
      "    Augmented Dickey-Fuller Test on \"SPY\" \n",
      " -----------------------------------------------\n",
      " Null Hypothesis: Data has unit root. Non-Stationary.\n",
      " Significance Level    = 0.05\n",
      " Test Statistic        = -1.9432\n",
      " No. Lags Chosen       = 2\n",
      " Critical value 1%     = -3.431\n",
      " Critical value 5%     = -2.862\n",
      " Critical value 10%    = -2.567\n",
      " => P-Value = 0.312. Weak evidence to reject the Null Hypothesis.\n",
      " => Series is Non-Stationary.\n",
      "\n",
      "\n",
      "    Augmented Dickey-Fuller Test on \"VXX\" \n",
      " -----------------------------------------------\n",
      " Null Hypothesis: Data has unit root. Non-Stationary.\n",
      " Significance Level    = 0.05\n",
      " Test Statistic        = -1.5409\n",
      " No. Lags Chosen       = 0\n",
      " Critical value 1%     = -3.431\n",
      " Critical value 5%     = -2.862\n",
      " Critical value 10%    = -2.567\n",
      " => P-Value = 0.5132. Weak evidence to reject the Null Hypothesis.\n",
      " => Series is Non-Stationary.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, column in stocks_data.iteritems():\n",
    "    util.adfuller_test(column, name=column.name)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eac0f7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_data_diff_1 = util.data_differencing(stocks_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7c659c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Augmented Dickey-Fuller Test on \"DIA\" \n",
      " -----------------------------------------------\n",
      " Null Hypothesis: Data has unit root. Non-Stationary.\n",
      " Significance Level    = 0.05\n",
      " Test Statistic        = -2726.1364\n",
      " No. Lags Chosen       = 0\n",
      " Critical value 1%     = -3.431\n",
      " Critical value 5%     = -2.862\n",
      " Critical value 10%    = -2.567\n",
      " => P-Value = 0.0. Rejecting Null Hypothesis.\n",
      " => Series is Stationary.\n",
      "\n",
      "\n",
      "    Augmented Dickey-Fuller Test on \"EEM\" \n",
      " -----------------------------------------------\n",
      " Null Hypothesis: Data has unit root. Non-Stationary.\n",
      " Significance Level    = 0.05\n",
      " Test Statistic        = -101.7824\n",
      " No. Lags Chosen       = 1\n",
      " Critical value 1%     = -3.431\n",
      " Critical value 5%     = -2.862\n",
      " Critical value 10%    = -2.567\n",
      " => P-Value = 0.0. Rejecting Null Hypothesis.\n",
      " => Series is Stationary.\n",
      "\n",
      "\n",
      "    Augmented Dickey-Fuller Test on \"QQQ\" \n",
      " -----------------------------------------------\n",
      " Null Hypothesis: Data has unit root. Non-Stationary.\n",
      " Significance Level    = 0.05\n",
      " Test Statistic        = -1855.4142\n",
      " No. Lags Chosen       = 0\n",
      " Critical value 1%     = -3.431\n",
      " Critical value 5%     = -2.862\n",
      " Critical value 10%    = -2.567\n",
      " => P-Value = 0.0. Rejecting Null Hypothesis.\n",
      " => Series is Stationary.\n",
      "\n",
      "\n",
      "    Augmented Dickey-Fuller Test on \"SPY\" \n",
      " -----------------------------------------------\n",
      " Null Hypothesis: Data has unit root. Non-Stationary.\n",
      " Significance Level    = 0.05\n",
      " Test Statistic        = -119.2653\n",
      " No. Lags Chosen       = 1\n",
      " Critical value 1%     = -3.431\n",
      " Critical value 5%     = -2.862\n",
      " Critical value 10%    = -2.567\n",
      " => P-Value = 0.0. Rejecting Null Hypothesis.\n",
      " => Series is Stationary.\n",
      "\n",
      "\n",
      "    Augmented Dickey-Fuller Test on \"VXX\" \n",
      " -----------------------------------------------\n",
      " Null Hypothesis: Data has unit root. Non-Stationary.\n",
      " Significance Level    = 0.05\n",
      " Test Statistic        = -37.407\n",
      " No. Lags Chosen       = 7\n",
      " Critical value 1%     = -3.431\n",
      " Critical value 5%     = -2.862\n",
      " Critical value 10%    = -2.567\n",
      " => P-Value = 0.0. Rejecting Null Hypothesis.\n",
      " => Series is Stationary.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, column in stocks_data_diff_1.iteritems():\n",
    "    util.adfuller_test(column, name=column.name)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2c434982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name   ::  Test Stat > C(95%)    =>   Signif  \n",
      " ----------------------------------------\n",
      "DIA    ::  9347.42   > 60.0627   =>   True\n",
      "EEM    ::  6571.19   > 40.1749   =>   True\n",
      "QQQ    ::  4644.69   > 24.2761   =>   True\n",
      "SPY    ::  3042.08   > 12.3212   =>   True\n",
      "VXX    ::  1511.19   > 4.1296    =>   True\n"
     ]
    }
   ],
   "source": [
    "cit = util.cointegration_test(stocks_data_diff_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3cdeb02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_data_diff_1.to_csv(os.path.join(processed_data_path, 'etf_data_diff_1.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca5dd78",
   "metadata": {},
   "source": [
    "### GDP Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1881b50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_data = pd.read_csv(os.path.join(processed_data_path, \"gdp_data.csv\"), index_col='DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "09286caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Augmented Dickey-Fuller Test on \"Tbill\" \n",
      " -----------------------------------------------\n",
      " Null Hypothesis: Data has unit root. Non-Stationary.\n",
      " Significance Level    = 0.05\n",
      " Test Statistic        = -1.613\n",
      " No. Lags Chosen       = 7\n",
      " Critical value 1%     = -3.463\n",
      " Critical value 5%     = -2.876\n",
      " Critical value 10%    = -2.574\n",
      " => P-Value = 0.4764. Weak evidence to reject the Null Hypothesis.\n",
      " => Series is Non-Stationary.\n",
      "\n",
      "\n",
      "    Augmented Dickey-Fuller Test on \"PPINSA\" \n",
      " -----------------------------------------------\n",
      " Null Hypothesis: Data has unit root. Non-Stationary.\n",
      " Significance Level    = 0.05\n",
      " Test Statistic        = 0.9446\n",
      " No. Lags Chosen       = 12\n",
      " Critical value 1%     = -3.464\n",
      " Critical value 5%     = -2.876\n",
      " Critical value 10%    = -2.575\n",
      " => P-Value = 0.9936. Weak evidence to reject the Null Hypothesis.\n",
      " => Series is Non-Stationary.\n",
      "\n",
      "\n",
      "    Augmented Dickey-Fuller Test on \"CPI\" \n",
      " -----------------------------------------------\n",
      " Null Hypothesis: Data has unit root. Non-Stationary.\n",
      " Significance Level    = 0.05\n",
      " Test Statistic        = 1.3099\n",
      " No. Lags Chosen       = 5\n",
      " Critical value 1%     = -3.462\n",
      " Critical value 5%     = -2.876\n",
      " Critical value 10%    = -2.574\n",
      " => P-Value = 0.9967. Weak evidence to reject the Null Hypothesis.\n",
      " => Series is Non-Stationary.\n",
      "\n",
      "\n",
      "    Augmented Dickey-Fuller Test on \"M1NSA\" \n",
      " -----------------------------------------------\n",
      " Null Hypothesis: Data has unit root. Non-Stationary.\n",
      " Significance Level    = 0.05\n",
      " Test Statistic        = 2.2009\n",
      " No. Lags Chosen       = 13\n",
      " Critical value 1%     = -3.464\n",
      " Critical value 5%     = -2.876\n",
      " Critical value 10%    = -2.575\n",
      " => P-Value = 0.9989. Weak evidence to reject the Null Hypothesis.\n",
      " => Series is Non-Stationary.\n",
      "\n",
      "\n",
      "    Augmented Dickey-Fuller Test on \"Unemp\" \n",
      " -----------------------------------------------\n",
      " Null Hypothesis: Data has unit root. Non-Stationary.\n",
      " Significance Level    = 0.05\n",
      " Test Statistic        = -2.5977\n",
      " No. Lags Chosen       = 9\n",
      " Critical value 1%     = -3.463\n",
      " Critical value 5%     = -2.876\n",
      " Critical value 10%    = -2.574\n",
      " => P-Value = 0.0935. Weak evidence to reject the Null Hypothesis.\n",
      " => Series is Non-Stationary.\n",
      "\n",
      "\n",
      "    Augmented Dickey-Fuller Test on \"IndProd\" \n",
      " -----------------------------------------------\n",
      " Null Hypothesis: Data has unit root. Non-Stationary.\n",
      " Significance Level    = 0.05\n",
      " Test Statistic        = -0.6848\n",
      " No. Lags Chosen       = 4\n",
      " Critical value 1%     = -3.462\n",
      " Critical value 5%     = -2.876\n",
      " Critical value 10%    = -2.574\n",
      " => P-Value = 0.8507. Weak evidence to reject the Null Hypothesis.\n",
      " => Series is Non-Stationary.\n",
      "\n",
      "\n",
      "    Augmented Dickey-Fuller Test on \"RGDP\" \n",
      " -----------------------------------------------\n",
      " Null Hypothesis: Data has unit root. Non-Stationary.\n",
      " Significance Level    = 0.05\n",
      " Test Statistic        = 0.7173\n",
      " No. Lags Chosen       = 2\n",
      " Critical value 1%     = -3.462\n",
      " Critical value 5%     = -2.875\n",
      " Critical value 10%    = -2.574\n",
      " => P-Value = 0.9902. Weak evidence to reject the Null Hypothesis.\n",
      " => Series is Non-Stationary.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, column in gdp_data.iteritems():\n",
    "    util.adfuller_test(column, name=column.name)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d6599b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_data_diff_1 = util.data_differencing(gdp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6b44067f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Augmented Dickey-Fuller Test on \"Tbill\" \n",
      " -----------------------------------------------\n",
      " Null Hypothesis: Data has unit root. Non-Stationary.\n",
      " Significance Level    = 0.05\n",
      " Test Statistic        = -4.8665\n",
      " No. Lags Chosen       = 14\n",
      " Critical value 1%     = -3.464\n",
      " Critical value 5%     = -2.876\n",
      " Critical value 10%    = -2.575\n",
      " => P-Value = 0.0. Rejecting Null Hypothesis.\n",
      " => Series is Stationary.\n",
      "\n",
      "\n",
      "    Augmented Dickey-Fuller Test on \"PPINSA\" \n",
      " -----------------------------------------------\n",
      " Null Hypothesis: Data has unit root. Non-Stationary.\n",
      " Significance Level    = 0.05\n",
      " Test Statistic        = -3.7818\n",
      " No. Lags Chosen       = 11\n",
      " Critical value 1%     = -3.463\n",
      " Critical value 5%     = -2.876\n",
      " Critical value 10%    = -2.575\n",
      " => P-Value = 0.0031. Rejecting Null Hypothesis.\n",
      " => Series is Stationary.\n",
      "\n",
      "\n",
      "    Augmented Dickey-Fuller Test on \"CPI\" \n",
      " -----------------------------------------------\n",
      " Null Hypothesis: Data has unit root. Non-Stationary.\n",
      " Significance Level    = 0.05\n",
      " Test Statistic        = -4.7671\n",
      " No. Lags Chosen       = 4\n",
      " Critical value 1%     = -3.462\n",
      " Critical value 5%     = -2.876\n",
      " Critical value 10%    = -2.574\n",
      " => P-Value = 0.0001. Rejecting Null Hypothesis.\n",
      " => Series is Stationary.\n",
      "\n",
      "\n",
      "    Augmented Dickey-Fuller Test on \"M1NSA\" \n",
      " -----------------------------------------------\n",
      " Null Hypothesis: Data has unit root. Non-Stationary.\n",
      " Significance Level    = 0.05\n",
      " Test Statistic        = 0.2277\n",
      " No. Lags Chosen       = 15\n",
      " Critical value 1%     = -3.464\n",
      " Critical value 5%     = -2.876\n",
      " Critical value 10%    = -2.575\n",
      " => P-Value = 0.9738. Weak evidence to reject the Null Hypothesis.\n",
      " => Series is Non-Stationary.\n",
      "\n",
      "\n",
      "    Augmented Dickey-Fuller Test on \"Unemp\" \n",
      " -----------------------------------------------\n",
      " Null Hypothesis: Data has unit root. Non-Stationary.\n",
      " Significance Level    = 0.05\n",
      " Test Statistic        = -4.8446\n",
      " No. Lags Chosen       = 11\n",
      " Critical value 1%     = -3.463\n",
      " Critical value 5%     = -2.876\n",
      " Critical value 10%    = -2.575\n",
      " => P-Value = 0.0. Rejecting Null Hypothesis.\n",
      " => Series is Stationary.\n",
      "\n",
      "\n",
      "    Augmented Dickey-Fuller Test on \"IndProd\" \n",
      " -----------------------------------------------\n",
      " Null Hypothesis: Data has unit root. Non-Stationary.\n",
      " Significance Level    = 0.05\n",
      " Test Statistic        = -6.1829\n",
      " No. Lags Chosen       = 3\n",
      " Critical value 1%     = -3.462\n",
      " Critical value 5%     = -2.876\n",
      " Critical value 10%    = -2.574\n",
      " => P-Value = 0.0. Rejecting Null Hypothesis.\n",
      " => Series is Stationary.\n",
      "\n",
      "\n",
      "    Augmented Dickey-Fuller Test on \"RGDP\" \n",
      " -----------------------------------------------\n",
      " Null Hypothesis: Data has unit root. Non-Stationary.\n",
      " Significance Level    = 0.05\n",
      " Test Statistic        = -8.8549\n",
      " No. Lags Chosen       = 1\n",
      " Critical value 1%     = -3.462\n",
      " Critical value 5%     = -2.875\n",
      " Critical value 10%    = -2.574\n",
      " => P-Value = 0.0. Rejecting Null Hypothesis.\n",
      " => Series is Stationary.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, column in gdp_data_diff_1.iteritems():\n",
    "    util.adfuller_test(column, name=column.name)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ed01efa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_data_diff_2 = util.data_differencing(gdp_data_diff_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "75d5ab37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Augmented Dickey-Fuller Test on \"Tbill\" \n",
      " -----------------------------------------------\n",
      " Null Hypothesis: Data has unit root. Non-Stationary.\n",
      " Significance Level    = 0.05\n",
      " Test Statistic        = -6.5132\n",
      " No. Lags Chosen       = 12\n",
      " Critical value 1%     = -3.464\n",
      " Critical value 5%     = -2.876\n",
      " Critical value 10%    = -2.575\n",
      " => P-Value = 0.0. Rejecting Null Hypothesis.\n",
      " => Series is Stationary.\n",
      "\n",
      "\n",
      "    Augmented Dickey-Fuller Test on \"PPINSA\" \n",
      " -----------------------------------------------\n",
      " Null Hypothesis: Data has unit root. Non-Stationary.\n",
      " Significance Level    = 0.05\n",
      " Test Statistic        = -7.9661\n",
      " No. Lags Chosen       = 11\n",
      " Critical value 1%     = -3.463\n",
      " Critical value 5%     = -2.876\n",
      " Critical value 10%    = -2.575\n",
      " => P-Value = 0.0. Rejecting Null Hypothesis.\n",
      " => Series is Stationary.\n",
      "\n",
      "\n",
      "    Augmented Dickey-Fuller Test on \"CPI\" \n",
      " -----------------------------------------------\n",
      " Null Hypothesis: Data has unit root. Non-Stationary.\n",
      " Significance Level    = 0.05\n",
      " Test Statistic        = -6.4335\n",
      " No. Lags Chosen       = 12\n",
      " Critical value 1%     = -3.464\n",
      " Critical value 5%     = -2.876\n",
      " Critical value 10%    = -2.575\n",
      " => P-Value = 0.0. Rejecting Null Hypothesis.\n",
      " => Series is Stationary.\n",
      "\n",
      "\n",
      "    Augmented Dickey-Fuller Test on \"M1NSA\" \n",
      " -----------------------------------------------\n",
      " Null Hypothesis: Data has unit root. Non-Stationary.\n",
      " Significance Level    = 0.05\n",
      " Test Statistic        = -3.6273\n",
      " No. Lags Chosen       = 14\n",
      " Critical value 1%     = -3.464\n",
      " Critical value 5%     = -2.876\n",
      " Critical value 10%    = -2.575\n",
      " => P-Value = 0.0053. Rejecting Null Hypothesis.\n",
      " => Series is Stationary.\n",
      "\n",
      "\n",
      "    Augmented Dickey-Fuller Test on \"Unemp\" \n",
      " -----------------------------------------------\n",
      " Null Hypothesis: Data has unit root. Non-Stationary.\n",
      " Significance Level    = 0.05\n",
      " Test Statistic        = -5.6834\n",
      " No. Lags Chosen       = 12\n",
      " Critical value 1%     = -3.464\n",
      " Critical value 5%     = -2.876\n",
      " Critical value 10%    = -2.575\n",
      " => P-Value = 0.0. Rejecting Null Hypothesis.\n",
      " => Series is Stationary.\n",
      "\n",
      "\n",
      "    Augmented Dickey-Fuller Test on \"IndProd\" \n",
      " -----------------------------------------------\n",
      " Null Hypothesis: Data has unit root. Non-Stationary.\n",
      " Significance Level    = 0.05\n",
      " Test Statistic        = -6.4278\n",
      " No. Lags Chosen       = 11\n",
      " Critical value 1%     = -3.463\n",
      " Critical value 5%     = -2.876\n",
      " Critical value 10%    = -2.575\n",
      " => P-Value = 0.0. Rejecting Null Hypothesis.\n",
      " => Series is Stationary.\n",
      "\n",
      "\n",
      "    Augmented Dickey-Fuller Test on \"RGDP\" \n",
      " -----------------------------------------------\n",
      " Null Hypothesis: Data has unit root. Non-Stationary.\n",
      " Significance Level    = 0.05\n",
      " Test Statistic        = -8.3304\n",
      " No. Lags Chosen       = 7\n",
      " Critical value 1%     = -3.463\n",
      " Critical value 5%     = -2.876\n",
      " Critical value 10%    = -2.574\n",
      " => P-Value = 0.0. Rejecting Null Hypothesis.\n",
      " => Series is Stationary.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, column in gdp_data_diff_2.iteritems():\n",
    "    util.adfuller_test(column, name=column.name)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bebc92bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_data_diff_2.to_csv(os.path.join(processed_data_path, 'gdp_data_diff_2.csv'), index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
